■Splunk trainng

★IFX
　フィールド抽出の正規表現を共有したり、自動で正規表現を作成することができる。

★Tag
host=www1とhost=www2のへdmzを設定し、host=dmzのように検索することが可能になる。
イベントタブの＞を押下して、アクションでタグ編集可能

★Event Type
同一の意味を持つログでもシステム毎に違っているので、一纏めにしてグループ化する。

イベントタイプとレポートどっちがいいか？
⇒検索の文字列を分類したい場合
⇒カテゴリを生成したい場合
⇒タイプの集計をしたい場合

eventtype=
上記コマンドで検索できる。


★ワークフローアクション
外部との連携がとれる。
　・get
　・search
　・post
 
　⇒get URLを設定して外部サイト連携できる。
 　（例）ipアドレスが不正かどうか外部サイトで確認ができる。
 
　⇒post get同じ
　　ヘッダーに情報を入れるか、セッションに入れて外部連携するかどうかの違い。
  
　⇒search
　　検索の文字列を入力する。
　　追加検索が行える感じ
  
　フィールドの変数は、$を使う　エスケープとしては、!をつける。$!のように。
 
 
★アラート
　⇒スケジュールアラート
　⇒リアルタイムアラート
 
 トリガーの条件
　・マッチするイベントがあれば（でふぉ）
　・件数より大きい
　・カスタムで検索式を記載して条件を設定できる
 
 アクティビティのアラートで実行されたアラートを確認できる。
 
 
★マクロ
　サーチ分を別名として定義できる。
　実行時は、バッククォートで囲ってあげると実行できるコマンドとなる。
　引数も渡すことが可能


★データモデル
　・イベント
　　⇒検索分を作成し、親子の関係を作成する。
　・サーチ
　　⇒マクロに似ている
　・トランザクション
　　⇒イベントかサーチができる状態作成する。
　　⇒バック処理でトランザクションコマンドが使われる。
  
データモデルを作成すると、高速化できる
※イベントだけ


Splunk Common infomation Model
正規化するデータモデルを提供してくれるapps
データモデルの共有もできる

プライベートだと高速化できない
しかし高速化してサマリ範囲を広げるとデータ容量をたくさん使用することになる。



12/1
◎Admin Traning

デート取り込み⇒データの加工⇒ディスクに書き込み⇒データの抽出
input⇒parsing⇒indexing⇒searching

サーチするのは、search heads
ディスク書き込み、データの加工、indexars
データ取り込み、fowarder


■Fowardar
データを集めて、indexersへデータを転送する。
univarsal Fowarder,heavy Fowarderの2種類がある。

■Indexer
データを取得し、加工して、ディスクに書き込む。
IOPSにIndexersに影響がある。。。


■Search head
1検索あたり、1コア使用する。
ユーザ多ければ、コアを増やすか、サーチヘッドを増やす。


NTPサーバの設定が必要。

プロセスについて
ディスクにアクセスるものがsplunkd 8089

Splunk Web 8000


★ライセンスについて
・Enterpriseトライアルライセンス
　⇒1日500MBまで
　⇒60日間限定のライセンスその後フリーライセンス
 
・フリーライセンス
　⇒1日500MBまで
　⇒クラスタ×、分散構成×、その他もろもろできない。
  
・Fowarderライセンス
　⇒Splunkサーバへ転送する。
　⇒書き込みはできない。
 
  /etc/licenses

・Enterpriseライセンス
　⇒制限なし
　
　ライセンスのプールが行える。
　ライセンスマスターサーバ分のライセンスがあればOK
　プールはデータを取り込む量を、分けることができる。
 500MBのライセンスなら、200MBと300MBみたいなかんじで。
 
★input.conf
データをGUIから追加する場合は、appsフォルダは以下のurlのフォルダのinput.confが編集される。


addonと呼ばれるAppは、Fowarderに関するもの。
　
 
sp_home/etc/...下に.confを配置する。

defaultとlocaのファイル
web上から変更する場合は、locaのディレクトリが更新される。
設定を変更（オーバライド）する場合は、defaultでディレクトリではなく、
localのディレクトリに設定がされる。こちらで設定する。

グローバル設定だとsystemフォルダから設定がされる。



12/2
★Forwarder
forwarderでは、splunktcp port転送します。
データのバーファーができます。
LBの機能もあります。
forwarder managementで集中管理できます。

★heavy forwarder
indexerへデータを連携する場合にルーティングを設定できる。
中間Fowarderとしての役目がある。
このデータは、このindexerみたいなデータを条件に設定できる。


indexerのinput.conf(recevingの設定をする)
↑
fwのoutput.conf,input.confを設定する。


圧縮転送する場合は、
compressed = trueを追加設定する。
input.conf(indexer側)
output.conf(fowarder側)
CPUに影響が多少はある。

SSLで転送する場合は。
圧縮時と同じファイルをなおす。


★indexer Acknowledgement
inderxerの取り込み確認ができるまで、
データを保持できる。


fowarderの配信
複数サーバがある場合いちいちやってられないので、
そのやり方。

サーバクラスを定義できる。

inputs.confを編集することで、
取り込むログのフィールドをある程度設定できる。




12/3
Script input
クーロンを設定するときは、
スクリプトから標準出力ではなくて、ファイル出力してその
ファイルをsplunkで取り込むような形にする。

moduler input
アドオンをダウンロードしてやる方法



windowsに限り、データの取り込み時に
データの加工が行える。

ローカルのデータなのかリモートのデータなのか（window編）
ドメインユーザで実行
WMIを使用する。

WMI input（リモートで取得）おすすめでない

windowsはローカルのログをguiで設定でき取得できる。


inputs.conf
 host
 source
 index
 sourcetype ⇒
 
props.confへ記載する。（ソースタイプの中身を記載するファイル）
 タイムスタンプ
 タイムゾーン
 イベント区切り位置
 イベントレベルの変換
 　　などなど。


props.confのスタンザは、3種（ファインチューニング）
ソースタイプ
source:ソース名
host:ホスト名



indexの使い方
アクセス制御でつかう。
・保存先のデータを見れるか見れないかなど制御時につかう。
・indexレベルでデータの保持期間とかそのあとに保存するのか削除するのかなどの
　ポリシーを設定できる。分けたい場合は、indexを分ける必要あり。
 
バケツ
・生データとindexデータ
・バケツにはステータスがある
　hot ⇒ warm ⇒ cold ⇒ frozen ⇒　archive or delete
 
　archiveデータは、thaweddbディレクトリに配置して復活させる。


 Retention Pokicies
 複数の日数が入っているバケツの場合、90に前のデータは退避させるが、
 開始日～終了日の終了日の日付から90日になるので、複数の日付がある場合は注意
 

★取り込んだデータを削除する方法
clean　または deleteコマンド
deleteは、adminでもできない。
can_deleteユーザ


12/4
ユーザとロール
ユーザの検索対象の時間などの設定ができる。


LDAPと連携させることでロールを割り当てできる。


パーシング
メタデータ⇒イベント⇒イベント（分解）

★props.confの設定について
・Line breaking
props.confへ以下の記述をすると、
一行一イベントとする。
SHOUD_LINEMARGE = false(デフォルト)
falseにする。

複数行の場合は、trueにする。
BREAK_ONLY_BEFORE_DATE=true(デフォルト)

・timestamp extraction
時間のタイムスタンプの設定
TIME_PREFIXどのデータを取得するか定義

TIME_FORMATで時間のフォーマットを定義

MAX_TIMESTAMP_LOOKAHEADで定義すると
PREFIXから何行目まで取得するか定義できる。

TZでタイムゾーンを設定


props.conf⇒transforms.conf
マスクが行える。

取り込むときにデータを除外できる。

_rawのデータがライセンス対象になる。


冗長化するとdupのライセンスがかかる。
クラスタにしたほうがいい。

リモートインストール

searsh head pooling

検索が遅くなってきたら
フォアーダよりインデックスの方がいい

スケジュールなどで同時検索数が増えた、画面で検索しない場合は、
job serverの構築を考えた方がいい。

同時でつかうユーザが増えた場合は、
ユーザアクセス用のを作る。

Capacity purannig


サーチのpoolingを使えば同時アクセス時対応できる
しかし、シェアストレージを作らないといけない。
6.2からサーチのクラスタリングもできるようになった。

・遅い理由
　スペックが悪い
　検索によってかわる。結果とかそれに。。
　レアサーチは、I/Oに起因する。
　インデクサーのI/Oがかなり。。。影響する。
　
 サマリーメソッド
 　・レポートアクセラレーション
  　　ここのレポートの高速化
   ・データモデルアクセラレーション
   ・サマリーインデキシング
　

クラスタリング機能
HA、DRどちらですか？要件を検討する。
マスター⇒ピア⇒サーチヘッドを作る。
UIから設定できる。server.confでもできる。
マスターノードがクラスタピアノデプロイメントサーバになる。感じ

outputs.conf
に記載すると、転送したデータがちゃんと取り込めたか完了したときに、
データを削除するかデータを取り込まれるまで待ってから削除するか
設定できる。


replication factor
rawデータのみ（リビルドが必要）

search factor
raw
index
の二つのデータ（リビルドが不要）


マルチサイトクラスタリング機能
DR


クラスタの構成時に、再起動などがあった時には、
サーバが落ちていると勘違いしてしまうので、
メンテナンスモードで再起動などを行うことで、
自動的にコピーされない。
しかし、ピアノードを再起動するときは注意して。




nfsはダメ、ssdのストレージで調査したい。
